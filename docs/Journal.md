# 15 June
- Found a recent StyleGAN2 [course](https://www.youtube.com/playlist?list=PLWuCzxqIpJs-l4OygaHssyydjOu-AWoHv) for artists having a video for audio reactive image generation, with some notebooks
- Created a project on MadeWithML, found pretrained models repo
- Found a similar website: [artbreeder](https://artbreeder.com/)

# 17 June
- GANSpace paper recommended
- Added tasks to the github project board

# 19 June
- Building and delivering products better than learning through a course and not having a project on hand. The real life top-down (compared to fast.ai). Go with the flow, if you can gauge your tasks, its enough. The whole project will always be ongoing.

# 20 June
- Suggestion to make proper [mind maps](miro.com) with knowns and unknowns

# 22 June
- Made a mind map on miro for the project and highlighted the unknowns

# 25 June
- Planned to understand StyleGAN by 30th
- The source of randomness for StyleGAN generator comes from a mapping network and a noise layer. [src](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/). These control the style. Need to learn more about it.
- StyleGAN uses PGGANs training style

# 26 June
- History of GANs: [vid](https://youtu.be/0d2WsXtQHR8)
- Inspiration and techniques: [vid](https://youtu.be/lYoIn1aL37s)
- Simple GAN implenentation in pytorch: [code](https://github.com/nbertagnolli/pytorch-simple-gan)
- Generator as an inverse-transform function: [blog](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)