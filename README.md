# Fusion Vision:
-- OPEN IN COLAB LINK for artists who can code and want to utilize a GPU

The idea behind this project is to build an end-to-end application where the user can control a novel image creation process by feeding in an audio snippet.

-- DEMO VIDEO/IMAGE HERE

# Inspiration
The inspiration came from an [artwork by prominent artist Mario Klingemann](https://youtu.be/A6bo_mIOto0) (*For the brave: play it at 0.25x if you want to see some eerie faces*).

# Technology
The latent spaces of a generative adversarial network called [StyleGAN2](https://github.com/NVlabs/stylegan2) will be explored based on the techniques used in the [GANSpace](https://github.com/harskish/ganspace) paper and interesting controls will be shortlisted. These controls are then mapped to an audio signal and can be controlled using a friendly user interface.

# How can I set it up?
See [SETUP.md](SETUP.md)

# Credits
- [Goku Mohandas](https://github.com/GokuMohandas/GokuMohandas) for the [summer 2020 incubator](https://madewithml.com/collections/7828/ds-incubator-summer-2020/)
- [Erik Härkönen](https://github.com/harskish) for the [GANspace](https://github.com/harskish/ganspace) project
- [Kim Seonghyeon](https://github.com/rosinality) for the [pytorch implementation of StyleGAN2](https://github.com/rosinality/stylegan2-pytorch)
- [Justin Pinkney](https://github.com/justinpinkney) for the list of [pretrained StyleGAN2 models](https://github.com/justinpinkney/awesome-pretrained-stylegan2)
- [Derrick Schultz](https://github.com/dvschultz) for the [StyleGAN2 workshop](https://www.youtube.com/playlist?list=PLWuCzxqIpJs-l4OygaHssyydjOu-AWoHv)

# License
The code of this repository is released under the [Apache 2.0](LICENSE) license.
